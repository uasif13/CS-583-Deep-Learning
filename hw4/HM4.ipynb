{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HM4.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlSk8lcnN3g7"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: Asif Uddin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv_ARwdxN3g9"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxQdwQCpN3g_"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwfNvxOaN3g_"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HCM3XaEN3hA",
        "outputId": "8a57f16c-82f5-4d55-a316-5bc60c1dad41"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NjWyGxlcsjkL",
        "outputId": "a49c0437-294c-4287-94f7-c8eccded30cc"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TZCqqokN3hA"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gYp1l80N3hB",
        "outputId": "9757ded7-d6e0-4257-b4f0-8a72ff19bc3b"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    b = numpy.zeros((y.size,num_class))\n",
        "    b[numpy.arange(y.size),y.reshape(y.size)] = 1\n",
        "    return b\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO4vSd7TN3hB"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kj928C-N3hC"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwszwOmnN3hD",
        "outputId": "58496734-f972-4fcb-c699-99e84abcaed7"
      },
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7ht3agkN3hE"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oANtDogiN3hG"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtTn3zUbN3hH",
        "outputId": "3982dc59-9c27-4dc3-e58f-5e5552d1f73f"
      },
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, BatchNormalization, Dropout, Activation\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_48 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpo37DvAN3hH"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-3 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGXT_RkPN3hI",
        "outputId": "8c136ac0-b2fb-4854-ad36-71a08cfeee6b"
      },
      "source": [
        "# Data Augmentation\n",
        "bs = 64\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2, \n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "it_train = datagen.flow(x_tr, y_tr, batch_size=bs)\n",
        "steps = int(x_tr.shape[0] / bs)\n",
        "history = model.fit(it_train, steps_per_epoch=steps, epochs=25, validation_data=(x_val, y_val))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "625/625 [==============================] - 26s 40ms/step - loss: 1.9286 - acc: 0.3255 - val_loss: 1.6037 - val_acc: 0.4488\n",
            "Epoch 2/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 1.4216 - acc: 0.4861 - val_loss: 1.2320 - val_acc: 0.5606\n",
            "Epoch 3/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 1.2383 - acc: 0.5545 - val_loss: 1.1430 - val_acc: 0.6076\n",
            "Epoch 4/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 1.1481 - acc: 0.5936 - val_loss: 1.1140 - val_acc: 0.6270\n",
            "Epoch 5/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 1.0650 - acc: 0.6191 - val_loss: 0.9612 - val_acc: 0.6584\n",
            "Epoch 6/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.9996 - acc: 0.6482 - val_loss: 0.9924 - val_acc: 0.6746\n",
            "Epoch 7/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.9585 - acc: 0.6629 - val_loss: 0.9130 - val_acc: 0.6921\n",
            "Epoch 8/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.9136 - acc: 0.6815 - val_loss: 0.8501 - val_acc: 0.7170\n",
            "Epoch 9/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.8859 - acc: 0.6961 - val_loss: 0.9070 - val_acc: 0.7028\n",
            "Epoch 10/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.8452 - acc: 0.7040 - val_loss: 0.7745 - val_acc: 0.7373\n",
            "Epoch 11/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.8312 - acc: 0.7098 - val_loss: 0.7925 - val_acc: 0.7356\n",
            "Epoch 12/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.8061 - acc: 0.7209 - val_loss: 0.7655 - val_acc: 0.7429\n",
            "Epoch 13/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.7918 - acc: 0.7281 - val_loss: 0.8564 - val_acc: 0.7155\n",
            "Epoch 14/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.7760 - acc: 0.7302 - val_loss: 0.8327 - val_acc: 0.7337\n",
            "Epoch 15/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.7548 - acc: 0.7376 - val_loss: 0.7776 - val_acc: 0.7492\n",
            "Epoch 16/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.7451 - acc: 0.7409 - val_loss: 0.6880 - val_acc: 0.7659\n",
            "Epoch 17/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.7272 - acc: 0.7485 - val_loss: 0.7588 - val_acc: 0.7509\n",
            "Epoch 18/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.7088 - acc: 0.7553 - val_loss: 0.7265 - val_acc: 0.7664\n",
            "Epoch 19/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.7006 - acc: 0.7579 - val_loss: 0.6708 - val_acc: 0.7761\n",
            "Epoch 20/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.6931 - acc: 0.7596 - val_loss: 0.6284 - val_acc: 0.7856\n",
            "Epoch 21/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.6760 - acc: 0.7673 - val_loss: 0.7001 - val_acc: 0.7664\n",
            "Epoch 22/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.6728 - acc: 0.7687 - val_loss: 0.6204 - val_acc: 0.7852\n",
            "Epoch 23/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.6734 - acc: 0.7689 - val_loss: 0.6919 - val_acc: 0.7779\n",
            "Epoch 24/25\n",
            "625/625 [==============================] - 24s 39ms/step - loss: 0.6600 - acc: 0.7707 - val_loss: 0.6764 - val_acc: 0.7783\n",
            "Epoch 25/25\n",
            "625/625 [==============================] - 24s 38ms/step - loss: 0.6573 - acc: 0.7710 - val_loss: 0.5964 - val_acc: 0.8018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "hFw59U4KN3hI",
        "outputId": "d3d51729-f548-421a-8b03-120b92524bd8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f963c18ff90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE3CnofQN3hI"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IynReEjJN3hJ"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr3ODwEGN3hK"
      },
      "source": [
        "# <Compile your model again (using the same hyper-parameters)>\n",
        "# ...\n",
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-3 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEkLG6SwN3hK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077f1104-b242-457f-d34e-de1732150d75"
      },
      "source": [
        "# <Train your model on the entire training set (50K samples)>\n",
        "# <Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "# <Do NOT use the validation_data option (because now you do\n",
        "# ...\n",
        "bs = 64\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2, \n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "it_train = datagen.flow(x_train, y_train_vec, batch_size=bs)\n",
        "history = model.fit(it_train, steps_per_epoch=x_train.shape[0]/bs, epochs=25)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "781/781 [==============================] - 30s 37ms/step - loss: 0.6651 - acc: 0.7694\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6484 - acc: 0.7753\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.6456 - acc: 0.7777\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6298 - acc: 0.7853\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6356 - acc: 0.7815\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.6232 - acc: 0.7834\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6070 - acc: 0.7882\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5920 - acc: 0.7972\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5959 - acc: 0.7944\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5891 - acc: 0.7930\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5896 - acc: 0.7987\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5773 - acc: 0.8002\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5811 - acc: 0.8014\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5712 - acc: 0.8049\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5713 - acc: 0.8043\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5614 - acc: 0.8070\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5588 - acc: 0.8055\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 29s 36ms/step - loss: 0.5465 - acc: 0.8115\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5541 - acc: 0.8098\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5557 - acc: 0.8100\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.5403 - acc: 0.8138\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5409 - acc: 0.8148\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5298 - acc: 0.8181\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5374 - acc: 0.8165\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5319 - acc: 0.8164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFnDzBDWN3hL"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCGoiU9vN3hM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40f7336-8eb2-4209-b022-570080e33415"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5443 - acc: 0.8193\n",
            "loss = 0.5443256497383118\n",
            "accuracy = 0.8192999958992004\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}